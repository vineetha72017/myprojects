{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN5EqbKr7XIa"
      },
      "source": [
        "Pixeltests School Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 1*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-yrdGbE7XId"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/pixeltests/datasets/main/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install pandas-profiling==2.*\n",
        "    \n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Hd7j4y7XIe"
      },
      "source": [
        "# Module Project: Decision Trees\n",
        "\n",
        "This week, the module projects will focus on creating and improving a model for the Tanazania Water Pump dataset. Your goal is to create a model to predict whether a water pump is functional, non-functional, or needs repair.\n",
        "\n",
        "Dataset source: [DrivenData.org](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/).\n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are as follows:\n",
        "\n",
        "- **Task 1:** Enter the [Kaggle](https://www.kaggle.com/t/6169ee7701164d24943c98eda2de9b5e) competition using exactly this link!\n",
        "- **Task 2:** Use `wrangle` function to import training and test data.\n",
        "- **Task 3:** Split training data into feature matrix `X` and target vector `y`.\n",
        "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
        "- **Task 5:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 6:** Build and train `model_dt`.\n",
        "- **Task 7:** Calculate the training and validation accuracy score for your model.\n",
        "- **Task 8:** Adjust model's `max_depth` to reduce overfitting.\n",
        "- **Task 9 `stretch goal`:** Create a horizontal bar chart showing the 10 most important features for your model.\n",
        "\n",
        "You should limit yourself to the following libraries for this project:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `pandas-profiling`\n",
        "- `sklearn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGcTuKnl7XIf"
      },
      "source": [
        "# Kaggle\n",
        "\n",
        "**Task 1:** Enter the [Kaggle](https://www.kaggle.com/t/6169ee7701164d24943c98eda2de9b5e) competition using exactly this link! **We recommend that you choose a username that's based on your name, since you might include it in your resume in the future.**. Go to the **Rules** page. Accept the rules of the competition. Notice that the **Rules** page also has instructions for the Submission process. The **Data** page has feature definitions.\n",
        "\n",
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzVslPYL7XIg"
      },
      "source": [
        "def wrangle(fm_path, tv_path=None):\n",
        "    if tv_path:\n",
        "        df = pd.merge(pd.read_csv(fm_path, \n",
        "                                  na_values=[0, -2.000000e-08]),\n",
        "                      pd.read_csv(tv_path)).set_index('id')\n",
        "    else:\n",
        "        df = pd.read_csv(fm_path, \n",
        "                         na_values=[0, -2.000000e-08],\n",
        "                         index_col='id')\n",
        "\n",
        "    # Drop constant columns\n",
        "    df.drop(columns=['recorded_by'], inplace=True)\n",
        "\n",
        "    # Drop HCCCs\n",
        "    cutoff = 100\n",
        "    drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "                 if df[col].nunique() > cutoff]\n",
        "    df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    # Drop duplicate columns\n",
        "    dupe_cols = [col for col in df.head(15).T.duplicated().index\n",
        "                 if df.head(15).T.duplicated()[col]]\n",
        "    df.drop(columns=dupe_cols, inplace=True)             \n",
        "\n",
        "    return df"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKWBckTD7XIg"
      },
      "source": [
        "**Task 1:** Using the `wrangle` function above, read the `train_features.csv` and  `train_labels.csv` files into the DataFrame `df`. Next, use the same function to read the test set `test_features.csv` into the DataFrame `X_test`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv0HQc3Q8Cqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca80aac-8867-4722-a3ff-02ae4c145901"
      },
      "source": [
        "import pandas as pd\n",
        "train_features_path='/content/train_features.csv'\n",
        "features_df=pd.read_csv(train_features_path,na_values=[0, -2.000000e-08])                                  \n",
        "labels_df=pd.read_csv('/content/train_labels.csv',na_values=[0, -2.000000e-08])\n",
        "X_test=pd.read_csv('/content/test_features.csv',na_values=[0, -2.000000e-08])\n",
        "features_df.shape,labels_df.shape\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 40), (47520, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_df['status_group']=labels_df['status_group'].values"
      ],
      "metadata": {
        "id": "DAOFEKqQMN00"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['recorded_by'], inplace=True)\n",
        "\n",
        "    # Drop HCCCs\n",
        "cutoff = 100\n",
        "drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "  if df[col].nunique() > cutoff]\n",
        "df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    # Drop duplicate columns\n",
        "dupe_cols = [col for col in df.head(15).T.duplicated().index\n",
        "  if df.head(15).T.duplicated()[col]]\n",
        "df.drop(columns=dupe_cols, inplace=True)             \n",
        "\n"
      ],
      "metadata": {
        "id": "nrutDA-z5Og1"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuAjWQ7k6_SM",
        "outputId": "18756a14-4c96-4fee-d045-b87dfe8f633b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47520, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.isnull().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSJrSJrA7NTE",
        "outputId": "c68dc0e5-7215-4018-821f-ae0dda683d3d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42693"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=features_df\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nax8Sduf6zep",
        "outputId": "0cdd4913-f751-45c2-edf9-b86821eb7748"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47520, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=features_df\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "tqW_CK5ptZR_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "b6252799-2c4f-44fe-e950-719a95ce243e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  amount_tsh  gps_height  longitude   latitude  num_private  \\\n",
              "0   1027.0        50.0       690.0  36.957086 -11.311964          NaN   \n",
              "1  16782.0         NaN         NaN  33.058573  -2.595762          NaN   \n",
              "\n",
              "                     basin  region  region_code  district_code  ...  \\\n",
              "0  Ruvuma / Southern Coast  Ruvuma           10            1.0  ...   \n",
              "1            Lake Victoria  Mwanza           19            2.0  ...   \n",
              "\n",
              "   payment_type water_quality quality_group quantity       source source_type  \\\n",
              "0    per bucket          soft          good   enough  machine dbh    borehole   \n",
              "1       monthly          soft          good   enough  machine dbh    borehole   \n",
              "\n",
              "  source_class              waterpoint_type waterpoint_type_group  \\\n",
              "0  groundwater  communal standpipe multiple    communal standpipe   \n",
              "1  groundwater                    hand pump             hand pump   \n",
              "\n",
              "              status_group  \n",
              "0  functional needs repair  \n",
              "1               functional  \n",
              "\n",
              "[2 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b898f1de-a3bf-41b3-a13d-21931bdc6d35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>amount_tsh</th>\n",
              "      <th>gps_height</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>num_private</th>\n",
              "      <th>basin</th>\n",
              "      <th>region</th>\n",
              "      <th>region_code</th>\n",
              "      <th>district_code</th>\n",
              "      <th>...</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>water_quality</th>\n",
              "      <th>quality_group</th>\n",
              "      <th>quantity</th>\n",
              "      <th>source</th>\n",
              "      <th>source_type</th>\n",
              "      <th>source_class</th>\n",
              "      <th>waterpoint_type</th>\n",
              "      <th>waterpoint_type_group</th>\n",
              "      <th>status_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1027.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>690.0</td>\n",
              "      <td>36.957086</td>\n",
              "      <td>-11.311964</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ruvuma / Southern Coast</td>\n",
              "      <td>Ruvuma</td>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>per bucket</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>machine dbh</td>\n",
              "      <td>borehole</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe multiple</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>functional needs repair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16782.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.058573</td>\n",
              "      <td>-2.595762</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lake Victoria</td>\n",
              "      <td>Mwanza</td>\n",
              "      <td>19</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>monthly</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>machine dbh</td>\n",
              "      <td>borehole</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b898f1de-a3bf-41b3-a13d-21931bdc6d35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b898f1de-a3bf-41b3-a13d-21931bdc6d35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b898f1de-a3bf-41b3-a13d-21931bdc6d35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su70Ql7c7XIg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop HCCCs\n",
        "def preprocess(df):\n",
        "  cutoff = 100\n",
        "  drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "            if df[col].nunique() > cutoff]\n",
        "  df.drop(columns=drop_cols, inplace=True)\n",
        "  # Drop duplicate columns\n",
        "  dupe_cols = [col for col in df.head(15).T.duplicated().index\n",
        "            if df.head(15).T.duplicated()[col]]\n",
        "  df.drop(columns=dupe_cols, inplace=True)        \n",
        "  #df.drop('id',axis=1,inplace=True)     \n",
        "  return df"
      ],
      "metadata": {
        "id": "ILpNnf6DPAiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.shape"
      ],
      "metadata": {
        "id": "bkipmwWOPDuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "gKjZlUsaPtBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "7KMQtwweCldt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=preprocess(features_df)\n",
        "train.shape"
      ],
      "metadata": {
        "id": "WFigEmXQXOmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=preprocess(X_test)\n",
        "X_test.head(2)"
      ],
      "metadata": {
        "id": "IZhl9xHLC04G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape\n",
        "#X_test.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "emtg_b_iDPNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6468RlEN7XIh"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 3:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'status_group'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUKkLI5C7XIh"
      },
      "source": [
        "X=df.drop('status_group',axis=1)\n",
        "y=labels_df\n",
        "X.shape,y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "189nVwIG9kZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.drop('id',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "y_xxc6fe-Tww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=train.drop('status_group',axis=1)\n",
        "X.shape"
      ],
      "metadata": {
        "id": "wMvl5U3uGPbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnTJe3Ul7XIi"
      },
      "source": [
        "**Task 4:** Using a randomized split, divide `X` and `y` into a training set (`X_train`, `y_train`) and a validation set (`X_val`, `y_val`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V6d31vc7XIi"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train1,val1=train_test_split(train,train_size=0.80,test_size=0.20,stratify=train['status_group'],random_state=42)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train1.shape,val1.shape"
      ],
      "metadata": {
        "id": "SMmTU8G-HC4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=train1.drop('status_group',axis=1)\n",
        "y_train=train1['status_group']\n",
        "X_val=val1.drop('status_group',axis=1)\n",
        "y_val=val1['status_group']"
      ],
      "metadata": {
        "id": "kiXrqeXp5UGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.shape,y_val.shape"
      ],
      "metadata": {
        "id": "GSHIpg2yJYeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,y_train.shape"
      ],
      "metadata": {
        "id": "pstV4pXmH-19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nMstK357XIi"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['status_group'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "9gvRX5NFKk6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred='functional'\n",
        "y_pred"
      ],
      "metadata": {
        "id": "irj9dfWoLCDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred=[0,0,0,0]\n",
        "y_true=[0,1,2,0]\n",
        "accuracy_score(y_true,y_pred)"
      ],
      "metadata": {
        "id": "93rTaTjwQES7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission_url='/content/tanzania sample solution.csv'\n",
        "sample_submission_df=pd.read_csv(sample_submission_url)\n",
        "sample_submission_df.shape"
      ],
      "metadata": {
        "id": "JglzEGfzRZmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "l=np.zeros((len(X_test),),dtype=int)\n",
        "l\n",
        "p=pd.DataFrame(l)\n",
        "p"
      ],
      "metadata": {
        "id": "fDV3KW3tSuJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred=pd.DataFrame(l)\n",
        "y_pred\n",
        "submission=sample_submission_df[['S.No.']].copy()\n",
        "submission['status_group']=y_pred\n",
        "submission.to_csv('baseline.csv',index=False)"
      ],
      "metadata": {
        "id": "z0PVtAsRUMuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvhzZGZR7XIi"
      },
      "source": [
        "baseline_acc = 0.50\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djjk3dff7XIj"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "**Task 6:** Build a `Pipeline` named `model_dt`, and fit it to your training data. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `DecisionTreeClassifier` predictor.\n",
        "\n",
        "**Note:** Don't forget to set the `random_state` parameter for your `DecisionTreeClassifier`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lxlE8_I7XIj"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "model_dt = make_pipeline(ce.OrdinalEncoder(),SimpleImputer(strategy='mean'),StandardScaler(),DecisionTreeClassifier(random_state=41))\n",
        "model_dt.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGJZT7uG7XIk"
      },
      "source": [
        "# V. Check Metrics\n",
        "\n",
        "**Task 7:** Calculate the training and validation accuracy scores for `model_dt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnPy5OPI7XIk"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "training_acc = accuracy_score(model_dt.predict(X_train),y_train)\n",
        "val_acc = accuracy_score(model_dt.predict(X_val),y_val)\n",
        "\n",
        "print('Training Accuracy Score:', training_acc)\n",
        "print('Validation Accuracy Score:', val_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6r1zyiz7XIk"
      },
      "source": [
        "# VI. Tune Model\n",
        "\n",
        "**Task 8:** Is there a large difference between your training and validation accuracy? If so, experiment with different setting for `max_depth` in your `DecisionTreeClassifier` to reduce the amount of overfitting in your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMBamA7F7XIk"
      },
      "source": [
        "#Yes..There is a large difference.\n",
        "model_dt1 = make_pipeline(ce.OrdinalEncoder(),SimpleImputer(strategy='mean'),StandardScaler(),DecisionTreeClassifier(max_depth=12,random_state=41))\n",
        "model_dt1.fit(X_train,y_train)\n",
        "\n",
        "print('Training Accuracy Score:', accuracy_score(model_dt1.predict(X_train),y_train))\n",
        "print('Validation Accuracy Score:', accuracy_score(model_dt1.predict(X_val),y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-nEtOzc7XIk"
      },
      "source": [
        "# VII. Communicate Results\n",
        "\n",
        "**Task 9 `stretch goal`:** Create a horizontal barchart that shows the the 10 most important features for model_dt, sorted by value.\n",
        "\n",
        "**Note:** [`DecisionTreeClassifier.feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreecla#sklearn.tree.DecisionTreeClassifier.feature_importances_) returns values that are different from [`LogisticRegression.coef_`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). All the values will be positive, and they will sum to `1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9sbtRpe7XIl"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#matplotlib inline\n",
        "\n",
        "coefficient=pd.Series(model_dt.namedsteps['DecisionTreeClassifier'].coef_[:45],X_train.columns)\n",
        "coeficient.sort_values().plot.barh(color='grey')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}