{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "rza67mqJhQtO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC68-65PG6zz",
        "outputId": "c26702b9-6ce9-49d9-b6d7-6e2efcc3aa0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data=pd.read_csv('/content/added_users.csv',encoding='latin1')\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "MshSSgWIej7O",
        "outputId": "0cabb94d-f7c7-4774-aaf5-5b4047a53498"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                name   screen_name  friends_count  \\\n",
              "0   22903             effeffe       effeffe            194   \n",
              "1   24503  Roberto Bonanzinga    Bonanzinga           1466   \n",
              "2  286543   Alessio Bragadini       abragad            535   \n",
              "3  382393        Ciro Cattuto          ciro            832   \n",
              "4  438023        fullcaffeine  fullcaffeine            444   \n",
              "\n",
              "                       created_at lang                   location  \\\n",
              "0  Sun Nov 26 15:19:32 +0000 2006   it              Napoli, Italy   \n",
              "1  Mon Nov 27 06:55:12 +0000 2006   en  Between Europe and the US   \n",
              "2  Wed Dec 27 14:55:17 +0000 2006   en               Milan, Italy   \n",
              "3  Sun Dec 31 02:03:17 +0000 2006   en           Torino, Piedmont   \n",
              "4  Tue Jan 02 09:01:50 +0000 2007   it                    Bologna   \n",
              "\n",
              "                                         description  \n",
              "0  L'uomo ha creato dio a sua immagine e somiglia...  \n",
              "1  Partner at Balderton Capital (formerly Benchma...  \n",
              "2          Web and social media developer from Italy  \n",
              "3  Research Director at ISI Foundation. Data scie...  \n",
              "4                                                NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03b243e7-1c74-4e73-b0cb-8855484c55fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>created_at</th>\n",
              "      <th>lang</th>\n",
              "      <th>location</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22903</td>\n",
              "      <td>effeffe</td>\n",
              "      <td>effeffe</td>\n",
              "      <td>194</td>\n",
              "      <td>Sun Nov 26 15:19:32 +0000 2006</td>\n",
              "      <td>it</td>\n",
              "      <td>Napoli, Italy</td>\n",
              "      <td>L'uomo ha creato dio a sua immagine e somiglia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24503</td>\n",
              "      <td>Roberto Bonanzinga</td>\n",
              "      <td>Bonanzinga</td>\n",
              "      <td>1466</td>\n",
              "      <td>Mon Nov 27 06:55:12 +0000 2006</td>\n",
              "      <td>en</td>\n",
              "      <td>Between Europe and the US</td>\n",
              "      <td>Partner at Balderton Capital (formerly Benchma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>286543</td>\n",
              "      <td>Alessio Bragadini</td>\n",
              "      <td>abragad</td>\n",
              "      <td>535</td>\n",
              "      <td>Wed Dec 27 14:55:17 +0000 2006</td>\n",
              "      <td>en</td>\n",
              "      <td>Milan, Italy</td>\n",
              "      <td>Web and social media developer from Italy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>382393</td>\n",
              "      <td>Ciro Cattuto</td>\n",
              "      <td>ciro</td>\n",
              "      <td>832</td>\n",
              "      <td>Sun Dec 31 02:03:17 +0000 2006</td>\n",
              "      <td>en</td>\n",
              "      <td>Torino, Piedmont</td>\n",
              "      <td>Research Director at ISI Foundation. Data scie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>438023</td>\n",
              "      <td>fullcaffeine</td>\n",
              "      <td>fullcaffeine</td>\n",
              "      <td>444</td>\n",
              "      <td>Tue Jan 02 09:01:50 +0000 2007</td>\n",
              "      <td>it</td>\n",
              "      <td>Bologna</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03b243e7-1c74-4e73-b0cb-8855484c55fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-03b243e7-1c74-4e73-b0cb-8855484c55fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-03b243e7-1c74-4e73-b0cb-8855484c55fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "7KlUvCg3l9oV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "#Import the WordNetLemmatizer class from the nltk.stem module\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "#Create an instance of the WordNetLemmatizer class\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "#Download the WordNet dataset\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#defining a function to lemmatize a text\n",
        "def lemmatize(word_to_lemmatize):\n",
        "  return(wnl.lemmatize(word_to_lemmatize))"
      ],
      "metadata": {
        "id": "RoWA5OS8JYR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0301b4-9f43-4d2b-ce89-3c19b282c518"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Importing the word_tokenize function from the nltk.tokenize module\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text_vector_mapping = {}\n",
        "\n",
        "# Preprocess text (example)\n",
        "# text1 = \"sdfdsf sfgfdsgfd sfdgdsg pant for boys.\"\n",
        "\n",
        "#Function to extract useful features from the text \n",
        "def word_embedding(input_text):\n",
        "    text2 = input_text\n",
        "    # tokens1 = word_tokenize(text1.lower())  # Tokenize and convert to lowercase\n",
        "    tokens2 = word_tokenize(text2.lower())  # Tokenize and convert to lowercase\n",
        "\n",
        "    # Train Word2Vec model (example)\n",
        "    model = Word2Vec(sentences=[tokens2], min_count=1, vector_size=100)\n",
        "\n",
        "    # Extract features using average word vectors\n",
        "    def extract_features(text):\n",
        "        tokens = word_tokenize(text.lower())  # Preprocess text\n",
        "        vectors = [model.wv[word] for word in tokens if word in model.wv]  # Get word vectors\n",
        "        if vectors:\n",
        "            avg_vector = sum(vectors) / len(vectors)  # Calculate average vector\n",
        "            return avg_vector\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    # Convert vector back to text\n",
        "    def vector_to_text(vector):\n",
        "        text = text_vector_mapping.get(tuple(vector), \"Vector representation not found.\")\n",
        "        return text\n",
        "\n",
        "    # Example usage\n",
        "    # features1 = extract_features(text1)\n",
        "    features2 = extract_features(text2)\n",
        "\n",
        "    # text_vector_mapping[tuple(features1)] = text1\n",
        "    text_vector_mapping[tuple(features2)] = text2\n",
        "\n",
        "    #Storing the final extracted text in extracted_text\n",
        "    extracted_text = vector_to_text(features2)\n",
        "\n",
        "    return extracted_text"
      ],
      "metadata": {
        "id": "AO8eOf28uNwC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8YdSR5LCFuD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "eM3qhrgvuib_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "w4ILjBDg7Njj",
        "outputId": "4aba875f-a653-4ca6-9043-5d5298ecd016"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                name   screen_name  friends_count  \\\n",
              "0   22903             effeffe       effeffe            194   \n",
              "1   24503  Roberto Bonanzinga    Bonanzinga           1466   \n",
              "2  286543   Alessio Bragadini       abragad            535   \n",
              "3  382393        Ciro Cattuto          ciro            832   \n",
              "4  438023        fullcaffeine  fullcaffeine            444   \n",
              "\n",
              "                       created_at lang                   location  \\\n",
              "0  Sun Nov 26 15:19:32 +0000 2006   it              Napoli, Italy   \n",
              "1  Mon Nov 27 06:55:12 +0000 2006   en  Between Europe and the US   \n",
              "2  Wed Dec 27 14:55:17 +0000 2006   en               Milan, Italy   \n",
              "3  Sun Dec 31 02:03:17 +0000 2006   en           Torino, Piedmont   \n",
              "4  Tue Jan 02 09:01:50 +0000 2007   it                    Bologna   \n",
              "\n",
              "                                         description  \n",
              "0  L'uomo ha creato dio a sua immagine e somiglia...  \n",
              "1  Partner at Balderton Capital (formerly Benchma...  \n",
              "2          Web and social media developer from Italy  \n",
              "3  Research Director at ISI Foundation. Data scie...  \n",
              "4                                                NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-583ca750-05b9-4d52-a9dd-2e0fc4b4eb43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>created_at</th>\n",
              "      <th>lang</th>\n",
              "      <th>location</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22903</td>\n",
              "      <td>effeffe</td>\n",
              "      <td>effeffe</td>\n",
              "      <td>194</td>\n",
              "      <td>Sun Nov 26 15:19:32 +0000 2006</td>\n",
              "      <td>it</td>\n",
              "      <td>Napoli, Italy</td>\n",
              "      <td>L'uomo ha creato dio a sua immagine e somiglia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24503</td>\n",
              "      <td>Roberto Bonanzinga</td>\n",
              "      <td>Bonanzinga</td>\n",
              "      <td>1466</td>\n",
              "      <td>Mon Nov 27 06:55:12 +0000 2006</td>\n",
              "      <td>en</td>\n",
              "      <td>Between Europe and the US</td>\n",
              "      <td>Partner at Balderton Capital (formerly Benchma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>286543</td>\n",
              "      <td>Alessio Bragadini</td>\n",
              "      <td>abragad</td>\n",
              "      <td>535</td>\n",
              "      <td>Wed Dec 27 14:55:17 +0000 2006</td>\n",
              "      <td>en</td>\n",
              "      <td>Milan, Italy</td>\n",
              "      <td>Web and social media developer from Italy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>382393</td>\n",
              "      <td>Ciro Cattuto</td>\n",
              "      <td>ciro</td>\n",
              "      <td>832</td>\n",
              "      <td>Sun Dec 31 02:03:17 +0000 2006</td>\n",
              "      <td>en</td>\n",
              "      <td>Torino, Piedmont</td>\n",
              "      <td>Research Director at ISI Foundation. Data scie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>438023</td>\n",
              "      <td>fullcaffeine</td>\n",
              "      <td>fullcaffeine</td>\n",
              "      <td>444</td>\n",
              "      <td>Tue Jan 02 09:01:50 +0000 2007</td>\n",
              "      <td>it</td>\n",
              "      <td>Bologna</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-583ca750-05b9-4d52-a9dd-2e0fc4b4eb43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-583ca750-05b9-4d52-a9dd-2e0fc4b4eb43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-583ca750-05b9-4d52-a9dd-2e0fc4b4eb43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "#Import the WordNetLemmatizer class from the nltk.stem module\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "#Create an instance of the WordNetLemmatizer class\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "#Download the WordNet dataset\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#defining a function to lemmatize a text\n",
        "def lemmatize(word_to_lemmatize):\n",
        "  return(wnl.lemmatize(word_to_lemmatize))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ftzow22Z8TmI",
        "outputId": "fdc42418-2f41-4980-8acf-efb5c25755e3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Importing the word_tokenize function from the nltk.tokenize module\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text_vector_mapping = {}\n",
        "\n",
        "# Preprocess text (example)\n",
        "# text1 = \"sdfdsf sfgfdsgfd sfdgdsg pant for boys.\"\n",
        "\n",
        "#Function to extract useful features from the text \n",
        "def word_embedding(input_text):\n",
        "    text2 = input_text\n",
        "    # tokens1 = word_tokenize(text1.lower())  # Tokenize and convert to lowercase\n",
        "    tokens2 = word_tokenize(text2.lower())  # Tokenize and convert to lowercase\n",
        "\n",
        "    # Train Word2Vec model (example)\n",
        "    model = Word2Vec(sentences=[tokens2], min_count=1, vector_size=100)\n",
        "\n",
        "    # Extract features using average word vectors\n",
        "    def extract_features(text):\n",
        "        tokens = word_tokenize(text.lower())  # Preprocess text\n",
        "        vectors = [model.wv[word] for word in tokens if word in model.wv]  # Get word vectors\n",
        "        if vectors:\n",
        "            avg_vector = sum(vectors) / len(vectors)  # Calculate average vector\n",
        "            return avg_vector\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    # Convert vector back to text\n",
        "    def vector_to_text(vector):\n",
        "        text = text_vector_mapping.get(tuple(vector), \"Vector representation not found.\")\n",
        "        return text\n",
        "\n",
        "    # Example usage\n",
        "    # features1 = extract_features(text1)\n",
        "    features2 = extract_features(text2)\n",
        "\n",
        "    # text_vector_mapping[tuple(features1)] = text1\n",
        "    text_vector_mapping[tuple(features2)] = text2\n",
        "\n",
        "    #Storing the final extracted text in extracted_text\n",
        "    extracted_text = vector_to_text(features2)\n",
        "\n",
        "    return extracted_text\n",
        "\n"
      ],
      "metadata": {
        "id": "zKnKRemL8xsf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import dot\n",
        "\n",
        "#Import the norm function from the numpy.linalg module\n",
        "from numpy.linalg import norm\n",
        "\n",
        "#Import the quote function from the urllib.parse module\n",
        "from urllib.parse import quote\n",
        "\n",
        "\n",
        "#creating resulting dataframe\n",
        "result_df = df[['id']].copy()\n"
      ],
      "metadata": {
        "id": "bwbaGtRn-OPK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_similarity1(df):\n",
        "  \n",
        "  #Defining two empty lists\n",
        "  cos_sim_values = []\n",
        "  \n",
        "  \n",
        "  #Run a loop to compute similarity between two vectors\n",
        "  for i in range(0,len(df)):\n",
        "      \n",
        "      #storing elements from the cell in Product_name\n",
        "      name = (df['name'][i:i+1])\n",
        "\n",
        "      #converting to string value\n",
        "      input_name = name.to_string()\n",
        "\n",
        "\n",
        "\n",
        "      #storing elements from the cell in Product_url_clean\n",
        "      screen_name = (df['screen_name'][i:i+1])\n",
        "\n",
        "      #converting to string value\n",
        "      input_screen_name = screen_name.to_string()\n",
        "\n",
        "      # Removing any digit association with the text\n",
        "      #screen_name = ''.join([m for m in screen_name if not m.isdigit()])\n",
        "      \n",
        "      description = (df['description'][i:i+1])\n",
        "\n",
        "      #converting to string value\n",
        "      input_description = description.to_string()\n",
        "\n",
        "      # Removing any digit association with the text\n",
        "      #description = ''.join([j for j in name if not j.isdigit()])\n",
        "\n",
        "\n",
        "      #splitting the words and storing it in dataframe\n",
        "      name_df = pd.DataFrame({\"Words\": input_name},index=[0])\n",
        "\n",
        "      #lookup for the frequency of the words\n",
        "      name_df_freq = pd.DataFrame(pd.crosstab(index=name_df['Words'],columns='count'))\n",
        "\n",
        "      #splitting the words and storing it in dataframe\n",
        "      screen_df = pd.DataFrame({\"Words1\": input_screen_name.split()})\n",
        "\n",
        "      #lookup for the frequency of the words\n",
        "      screen_df_freq = pd.DataFrame(pd.crosstab(index=screen_df['Words1'],columns='count'))\n",
        "\n",
        "      description_df = pd.DataFrame({\"Words2\": input_description.split()})\n",
        "\n",
        "      #lookup for the frequency of the words\n",
        "      description_df_freq = pd.DataFrame(pd.crosstab(index=description_df['Words2'],columns='count'))\n",
        "\n",
        "      #concat the dfs\n",
        "      dfs = [name_df_freq, screen_df_freq]\n",
        "      all_words = pd.concat(dfs, axis=1)\n",
        "      dfs1=[name_df_freq,description_df_freq]\n",
        "      all_words1 = pd.concat(dfs1, axis=1)\n",
        "      dfs2=[screen_df_freq,description_df_freq]\n",
        "      all_words2 = pd.concat(dfs2, axis=1)\n",
        "\n",
        "      # Substituting the NAN with zeros\n",
        "      all_words = all_words.fillna(0)\n",
        "      all_words.columns = [\"name_data\", \"screen_data\"]\n",
        "      all_words1= all_words.fillna(0)\n",
        "      all_words1.columns=[\"name_data\",\"description_data\"]\n",
        "      all_words2= all_words.fillna(0)\n",
        "      all_words2.columns=[\"screen_data\",\"description_data\"]\n",
        "      #computing the cosine values\n",
        "      cos_sim = dot(all_words[\"name_data\"], all_words[\"screen_data\"])/(norm(all_words[\"name_data\"])*norm(all_words[\"screen_data\"]))\n",
        "      cos_sim = dot(all_words1[\"name_data\"], all_words1[\"description_data\"])/(norm(all_words1[\"name_data\"])*norm(all_words1[\"description_data\"]))\n",
        "      cos_sim = dot(all_words2[\"screen_data\"], all_words2[\"description_data\"])/(norm(all_words2[\"screen_data\"])*norm(all_words2[\"description_data\"]))\n",
        "\n",
        "      #append the values in the corresponding lists\n",
        "      cos_sim_values.append(cos_sim)\n",
        "\n",
        "  #storing the above lists values in the newly created column        \n",
        "  df['cos_sim_values'] = cos_sim_values\n",
        "\n",
        "  #Return the value\n",
        "  return df"
      ],
      "metadata": {
        "id": "Hhxu53XYmbHg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YA2dSoBzurWv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUb_7I5bZIeC",
        "outputId": "06f84ec3-9032-465c-9f8b-2bc68a8bd5b9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'screen_name', 'friends_count', 'created_at', 'lang',\n",
              "       'location', 'description'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "#calling the function to extract useful features\n",
        "\n",
        "# calling the function to measure cosine similarity\n",
        "result_df = compute_similarity1(df) \n",
        "\n",
        "#sorting the cosine values in order of highest values in the top\n",
        "result_df = result_df.sort_values(by='cos_sim_values', ascending=False)\n",
        "\n",
        "#Displaying the result after the above-mentioned operations\n",
        "result_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "SyExeihb_dY5",
        "outputId": "510d2e4c-5081-44f2-9d8d-a292ead951b6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id                  name     screen_name  friends_count  \\\n",
              "0        22903               effeffe         effeffe            194   \n",
              "382  281234838  Elisabetta Bianchini  bettabianchini             29   \n",
              "376  267989312         Fabio Papotti       fabiop953            254   \n",
              "377  271374532          Bluest Blues    bluestblues1             48   \n",
              "378  272121120          Carlo Bonini        cmbonini             93   \n",
              "\n",
              "                         created_at lang       location  \\\n",
              "0    Sun Nov 26 15:19:32 +0000 2006   it  Napoli, Italy   \n",
              "382  Tue Apr 12 22:20:57 +0000 2011   it            NaN   \n",
              "376  Thu Mar 17 23:19:19 +0000 2011   it          Italy   \n",
              "377  Thu Mar 24 11:24:05 +0000 2011   it          Praga   \n",
              "378  Fri Mar 25 21:47:12 +0000 2011   it            NaN   \n",
              "\n",
              "                                           description  cos_sim_values  \n",
              "0    L'uomo ha creato dio a sua immagine e somiglia...             0.0  \n",
              "382                                Let's think please!             0.0  \n",
              "376                          The better is yet to come             0.0  \n",
              "377                                                NaN             0.0  \n",
              "378                               NON sono giornalista             0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a57743d2-ca8b-4b06-94d0-15f324ee5726\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>created_at</th>\n",
              "      <th>lang</th>\n",
              "      <th>location</th>\n",
              "      <th>description</th>\n",
              "      <th>cos_sim_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22903</td>\n",
              "      <td>effeffe</td>\n",
              "      <td>effeffe</td>\n",
              "      <td>194</td>\n",
              "      <td>Sun Nov 26 15:19:32 +0000 2006</td>\n",
              "      <td>it</td>\n",
              "      <td>Napoli, Italy</td>\n",
              "      <td>L'uomo ha creato dio a sua immagine e somiglia...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>281234838</td>\n",
              "      <td>Elisabetta Bianchini</td>\n",
              "      <td>bettabianchini</td>\n",
              "      <td>29</td>\n",
              "      <td>Tue Apr 12 22:20:57 +0000 2011</td>\n",
              "      <td>it</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Let's think please!</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>267989312</td>\n",
              "      <td>Fabio Papotti</td>\n",
              "      <td>fabiop953</td>\n",
              "      <td>254</td>\n",
              "      <td>Thu Mar 17 23:19:19 +0000 2011</td>\n",
              "      <td>it</td>\n",
              "      <td>Italy</td>\n",
              "      <td>The better is yet to come</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>271374532</td>\n",
              "      <td>Bluest Blues</td>\n",
              "      <td>bluestblues1</td>\n",
              "      <td>48</td>\n",
              "      <td>Thu Mar 24 11:24:05 +0000 2011</td>\n",
              "      <td>it</td>\n",
              "      <td>Praga</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>272121120</td>\n",
              "      <td>Carlo Bonini</td>\n",
              "      <td>cmbonini</td>\n",
              "      <td>93</td>\n",
              "      <td>Fri Mar 25 21:47:12 +0000 2011</td>\n",
              "      <td>it</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NON sono giornalista</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a57743d2-ca8b-4b06-94d0-15f324ee5726')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a57743d2-ca8b-4b06-94d0-15f324ee5726 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a57743d2-ca8b-4b06-94d0-15f324ee5726');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Importing the word_tokenize function from the nltk.tokenize module\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text_vector_mapping = {}\n",
        "\n",
        "# Preprocess text (example)\n",
        "# text1 = \"sdfdsf sfgfdsgfd sfdgdsg pant for boys.\"\n",
        "\n",
        "#Function to extract useful features from the text \n",
        "def word_embedding(input_text):\n",
        "    text2 = input_text\n",
        "    # tokens1 = word_tokenize(text1.lower())  # Tokenize and convert to lowercase\n",
        "    tokens2 = word_tokenize(text2.lower())  # Tokenize and convert to lowercase\n",
        "\n",
        "    # Train Word2Vec model (example)\n",
        "    model = Word2Vec(sentences=[tokens2], min_count=1, vector_size=100)\n",
        "\n",
        "    # Extract features using average word vectors\n",
        "    def extract_features(text):\n",
        "        tokens = word_tokenize(text.lower())  # Preprocess text\n",
        "        vectors = [model.wv[word] for word in tokens if word in model.wv]  # Get word vectors\n",
        "        if vectors:\n",
        "            avg_vector = sum(vectors) / len(vectors)  # Calculate average vector\n",
        "            return avg_vector\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    # Convert vector back to text\n",
        "    def vector_to_text(vector):\n",
        "        text = text_vector_mapping.get(tuple(vector), \"Vector representation not found.\")\n",
        "        return text\n",
        "\n",
        "    # Example usage\n",
        "    # features1 = extract_features(text1)\n",
        "    features2 = extract_features(text2)\n",
        "\n",
        "    # text_vector_mapping[tuple(features1)] = text1\n",
        "    text_vector_mapping[tuple(features2)] = text2\n",
        "\n",
        "    #Storing the final extracted text in extracted_text\n",
        "    extracted_text = vector_to_text(features2)\n",
        "\n",
        "    return extracted_text"
      ],
      "metadata": {
        "id": "n-dkCovC_1mE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Importing the word_tokenize function from the nltk.tokenize module\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text_vector_mapping = {}\n",
        "\n",
        "# Preprocess text (example)\n",
        "# text1 = \"sdfdsf sfgfdsgfd sfdgdsg pant for boys.\"\n",
        "\n",
        "#Function to extract useful features from the text \n",
        "def word_embedding(input_text):\n",
        "    text2 = input_text\n",
        "    # tokens1 = word_tokenize(text1.lower())  # Tokenize and convert to lowercase\n",
        "    tokens2 = word_tokenize(text2.lower())  # Tokenize and convert to lowercase\n",
        "\n",
        "    # Train Word2Vec model (example)\n",
        "    model = Word2Vec(sentences=[tokens2], min_count=1, vector_size=100)\n",
        "\n",
        "    # Extract features using average word vectors\n",
        "    def extract_features(text):\n",
        "        tokens = word_tokenize(text.lower())  # Preprocess text\n",
        "        vectors = [model.wv[word] for word in tokens if word in model.wv]  # Get word vectors\n",
        "        if vectors:\n",
        "            avg_vector = sum(vectors) / len(vectors)  # Calculate average vector\n",
        "            return avg_vector\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    # Convert vector back to text\n",
        "    def vector_to_text(vector):\n",
        "        text = text_vector_mapping.get(tuple(vector), \"Vector representation not found.\")\n",
        "        return text\n",
        "\n",
        "    # Example usage\n",
        "    # features1 = extract_features(text1)\n",
        "    features2 = extract_features(text2)\n",
        "\n",
        "    # text_vector_mapping[tuple(features1)] = text1\n",
        "    text_vector_mapping[tuple(features2)] = text2\n",
        "\n",
        "    #Storing the final extracted text in extracted_text\n",
        "    extracted_text = vector_to_text(features2)\n",
        "\n",
        "    return extracted_text"
      ],
      "metadata": {
        "id": "AmuF9U4vkOf7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_embedding(input_text):\n",
        "    text2 = input_text\n",
        "    # tokens1 = word_tokenize(text1.lower())  # Tokenize and convert to lowercase\n",
        "    tokens2 = word_tokenize(text2.lower())  # Tokenize and convert to lowercase\n",
        "\n",
        "    # Train Word2Vec model (example)\n",
        "    model = Word2Vec(sentences=[tokens2], min_count=1, vector_size=100)\n",
        "\n",
        "    # Extract features using average word vectors\n",
        "    def extract_features(text):\n",
        "        tokens = word_tokenize(text.lower())  # Preprocess text\n",
        "        vectors = [model.wv[word] for word in tokens if word in model.wv]  # Get word vectors\n",
        "        if vectors:\n",
        "            avg_vector = sum(vectors) / len(vectors)  # Calculate average vector\n",
        "            return avg_vector\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    # Convert vector back to text\n",
        "    def vector_to_text(vector):\n",
        "        text = text_vector_mapping.get(tuple(vector), \"Vector representation not found.\")\n",
        "        return text\n",
        "\n",
        "    # Example usage\n",
        "    # features1 = extract_features(text1)\n",
        "    features2 = extract_features(text2)\n",
        "\n",
        "    # text_vector_mapping[tuple(features1)] = text1\n",
        "    text_vector_mapping[tuple(features2)] = text2\n",
        "\n",
        "    #Storing the final extracted text in extracted_text\n",
        "    extracted_text = vector_to_text(features2)\n",
        "\n",
        "    return extracted_text"
      ],
      "metadata": {
        "id": "1ujsQczYjyOr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_fEvtg1JlJz5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmBEXXq3owK6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bMm8r7wyoc4N"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "znVo-KR0wg0g"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9s5p266zoMzn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58_jrj3DsJO5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gwqs5ZVMq3Tp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iGvGAV-nlfqE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yTx2oouWnUFX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XdMRWrTQnmDp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P8Wb1CYVn4U1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nmCR_9f_RDk3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9FZZ3cnjgG82"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eT8DNs8xfqv4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sWNR414AhJsX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kt00wfMRjfAm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "prb8wjzEhcEs"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDAM74PzNdLX",
        "outputId": "1bc9500f-2e83-4336-87e1-ff949cb0f0b0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'name', 'screen_name', 'friends_count', 'created_at', 'lang',\n",
              "       'location', 'description', 'cos_sim_values'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6kEe4YRMjD_s"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qOHoKtufSikL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N8JrM1FqSabT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8sFgqkimSvaZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Zuh785FkknC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R391U02Flo3W"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6zKt3Pd1_5tX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BlqlRSveNlk5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RonimE2UGVMq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VeIoE1gJHYFm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3-Xwhtw8BgLu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oTMhxKA8Z76J"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1jsaeIt_alRA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtlHDSH6VvrE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PcRDCUcqLAdC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6nmKu5BVQIBc"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F8pjaC-UQgW5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dELvzWqvQklx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k26tYse7Qz5q"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SpSAFhqlPtQT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "INPTemTFMApZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xbDM1yWUNouv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "86JAbVWxRvv8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XJnlzegPNqiY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "11lGOM8tNWEn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Yg-FJEaPgwo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rMh5kwgvPEfk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8w2zAK70XSrX"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}